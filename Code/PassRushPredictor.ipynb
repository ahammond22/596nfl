{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d79596e-bc1d-4e28-afa0-f5fa98161d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import animation\n",
    "from matplotlib.animation import FFMpegWriter\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import datetime\n",
    "import glob\n",
    "import ast\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a895a20-3a47-4f3c-8fe0-6eaaa2601201",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df    = pd.read_csv(\"/home/jovyan/596nfl/Data/games.csv\")\n",
    "scouting_df = pd.read_csv(\"/home/jovyan/596nfl/Data/pffScoutingData.csv\")\n",
    "players_df  = pd.read_csv(\"/home/jovyan/596nfl/Data/players.csv\")\n",
    "plays_df    = pd.read_csv(\"/home/jovyan/596nfl/Data/plays.csv\")\n",
    "\n",
    "week1_df = pd.read_csv(\"/home/jovyan/596nfl/Data/week1.csv\")\n",
    "week2_df = pd.read_csv(\"/home/jovyan/596nfl/Data/week2.csv\")\n",
    "week3_df = pd.read_csv(\"/home/jovyan/596nfl/Data/week3.csv\")\n",
    "week4_df = pd.read_csv(\"/home/jovyan/596nfl/Data/week4.csv\")\n",
    "week5_df = pd.read_csv(\"/home/jovyan/596nfl/Data/week5.csv\")\n",
    "week6_df = pd.read_csv(\"/home/jovyan/596nfl/Data/week6.csv\")\n",
    "week7_df = pd.read_csv(\"/home/jovyan/596nfl/Data/week7.csv\")\n",
    "week8_df = pd.read_csv(\"/home/jovyan/596nfl/Data/week8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc52c185-f27e-4202-aa51-08db010a7bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [week1_df, week2_df, week3_df, week4_df, week5_df, week6_df, week7_df, week8_df]\n",
    "tracking = pd.concat(frames)\n",
    "\n",
    "tracking = tracking[tracking.x.notnull()]\n",
    "tracking = tracking[tracking.y.notnull()]\n",
    "\n",
    "# Prepare for too few/many men on the field error\n",
    "filter_out     = tracking.groupby(['gameId', 'playId', 'frameId'])['nflId'].count()\n",
    "filter_out_ids = filter_out[filter_out != 22].index\n",
    "\n",
    "tracking_ids = tracking.set_index(['gameId', 'playId', 'frameId']).index\n",
    "tracking = tracking[~tracking_ids.isin(filter_out_ids)]\n",
    "\n",
    "tracking['nflId'] = tracking['nflId'].fillna(-1).astype(int)\n",
    "tracking_football = tracking[tracking.team == 'football']\n",
    "tracking = tracking.merge(players_df[['nflId', 'officialPosition']], on = 'nflId') # If af any nflIds are nan, then they will be removed via the 'inner' merge\n",
    "\n",
    "scouting_df = scouting_df.merge(players_df[['nflId', 'officialPosition']], on ='nflId', how = 'inner') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "378b252d-eb24-4b4d-b285-71ea588d5501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8045\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "def get_play_df(frames=[1,3,5], gameId = None, playId = None):\n",
    "    if playId is not None and gameId is not None:\n",
    "        play_df = tracking[(tracking.gameId == gameId) & (tracking.playId == playId)]\n",
    "    else:\n",
    "        play_df = tracking\n",
    "        \n",
    "    if frames == 'all':\n",
    "        max_frame = int(play_df.frameId.max())\n",
    "        \n",
    "        frames = np.linspace(1, max_frame, max_frame).astype(int)\n",
    "    play_df = play_df[(play_df['frameId'].isin(frames))] # Ball snapped in frame 6 - this allows us to get variation in player positioning without adding augmentation that could mess with the data integrity\n",
    "    # play_df = scouting_df.merge(play_df, on = ['gameId', 'playId', 'nflId', 'officialPosition'], how='inner').reset_index()\n",
    "    play_df = scouting_df.merge(play_df, on=['gameId', 'playId', 'nflId', 'officialPosition'], how='inner').reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    play_df['gamePlayId']  = play_df.gameId.astype(str) + play_df.playId.astype(str) + '_' + play_df.frameId.astype(str)\n",
    "    play_df['IsOnDefense'] = play_df['pff_role'].isin(['Coverage', 'Pass Rush']).astype(int)\n",
    "    play_df['passRusher']  = play_df['pff_role'].eq('Pass Rush').astype(int)\n",
    "    play_df['blitzId'] = 0\n",
    "    secondary_blitz_ids = play_df[(play_df['pff_positionLinedUp'].isin(['FS', 'SSL', 'SSR', 'SCBR', 'SCBL', 'SCBiL', 'SCBiR', 'SCBoL', 'SCBoR', 'RCB',  'LCB']) & (play_df['pff_role'] == 'Pass Rush'))].gamePlayId.unique()\n",
    "    LB_blitz_ids = play_df[(play_df['pff_positionLinedUp'].isin(['ROLB', 'RILB', 'LILB', 'LOLB', 'LLB', 'MLB', 'RLB']) & (play_df['pff_role'] == 'Pass Rush'))].gamePlayId.unique()\n",
    "    play_df.loc[play_df.index, 'isBlocked'] = 0\n",
    "    play_df.loc[play_df.gamePlayId.isin(secondary_blitz_ids), 'blitzId'] = 1\n",
    "    play_df.loc[play_df.gamePlayId.isin(LB_blitz_ids), 'blitzId'] = 2\n",
    "    return play_df\n",
    "\n",
    "presnap_df = get_play_df()\n",
    "\n",
    "# Split train and val: Arbitrarily chose 17 because the train/val sizes came out to be ~9/1\n",
    "presnap_df_train = presnap_df[presnap_df.playId % 17 != 0]\n",
    "presnap_df_val = presnap_df[presnap_df.playId % 17 == 0]\n",
    "# print(len(presnap_df_train[presnap_df.frameId == 1].gamePlayId.unique()))\n",
    "# print(len(presnap_df_val[presnap_df.frameId == 1].gamePlayId.unique()))\n",
    "print(len(presnap_df_train.loc[presnap_df_train.frameId == 1, 'gamePlayId'].unique()))\n",
    "print(len(presnap_df_val.loc[presnap_df_val.frameId == 1, 'gamePlayId'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e44fb8-7320-4264-9894-9b1873414599",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlitzDataset(Dataset):\n",
    "    def __init__(self, init_df, excluded_pos_list = ['C'], ratio_use = 1.0, metrics = ['x_to_ball', 'y_to_ball', 'dir'], standardize_type = None, order = 'left-to-right', training = True):\n",
    "        self.ratio_use = ratio_use # Useful for quickly testing framework\n",
    "        ids = init_df.gamePlayId.unique()\n",
    "        ids = ids[:int(len(ids) * ratio_use)]\n",
    "        init_df = init_df[init_df.gamePlayId.isin(ids)]\n",
    "        init_df = self.apply_augmentation(init_df) if training else init_df\n",
    "        self.presnap_df = init_df.groupby('gamePlayId')\n",
    "        self.pos_keys = {'NT': 0, 'DT': 1, 'DE': 2, 'LB': 3, 'CB': 4, 'FS': 5, 'SS': 6, 'other': 7}\n",
    "        self.order = order\n",
    "        self.STANDARDIZE_TYPE = standardize_type\n",
    "        self.EXCLUDED_POS     = excluded_pos_list\n",
    "        self.METRICS          = metrics\n",
    "        self.INFO_METRICS     = [m for m in self.METRICS if 'info' in m] # 'info' pertains to the situation (yardline, quarter, point diff, etc.) data\n",
    "        self.NUM_PLAYS        = len(init_df.gamePlayId.unique())\n",
    "        self.NUM_OFFENSIVE    = 11 - len(self.EXCLUDED_POS)\n",
    "        self.NUM_DEFENSIVE    = 11\n",
    "        self.NUM_METRICS      = 4 + len(self.METRICS[2:]) # Only do 'x/y_to_ball' for both offensive and defensive, every other metric (dir, orientation, etc.) just defense \n",
    "        self.get_dataset(self.presnap_df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.NUM_PLAYS\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        out_dict = {'labels':{}}\n",
    "\n",
    "        out_dict['data'] = self.tensor[idx]\n",
    "        out_dict['labels']['gamePlayId']       = self.playIds[idx]\n",
    "        out_dict['labels']['isRusher']         = self.labels[idx]\n",
    "        out_dict['labels']['playerIds']        = self.playerIds[idx]\n",
    "        out_dict['labels']['blitzId']          = self.blitzIds[idx]\n",
    "        out_dict['labels']['playerPosLinedUp'] = self.playerPosLinedUp[idx]\n",
    "        out_dict['labels']['playerPos']        = self.playerPos[idx]\n",
    "        out_dict['labels']['isBlocked']        = self.playerBlocked[idx]\n",
    "        out_dict['labels']['pff_sack']         = self.playerSacks[idx]\n",
    "        out_dict['labels']['pff_hurry']        = self.playerHurries[idx]\n",
    "        out_dict['labels']['pff_hit']          = self.playerHits[idx]\n",
    "        return out_dict\n",
    "    \n",
    "    def get_position_key(self, row):\n",
    "        officialPos = row['officialPosition'].replace(\"M\",\"\").replace(\"O\",\"\").replace(\"I\",\"\") # Get 'LB' instead of OLB/MLB/ILB\n",
    "        key = self.pos_keys[officialPos if officialPos in self.pos_keys.keys() else 'other']\n",
    "        return key\n",
    "\n",
    "    # def apply_augmentation(self, df):\n",
    "    #     # Flipping Plays in the y direction (sideline to sideline)\n",
    "    #     sample_ids = np.random.choice(df.gamePlayId.unique(), int(0.5*len(df.gamePlayId.unique())))\n",
    "    #     df_sample = df.loc[df.gamePlayId.isin(sample_ids)]\n",
    "    #     df_sample['y'] *= -1\n",
    "\n",
    "    #     df_sample['gamePlayId'] = df_sample['gamePlayId'].apply(lambda x: x+'_flipped')\n",
    "    #     if 'o' in df_sample.keys():\n",
    "    #         df_sample['o'] = df_sample['o'] + 180.0\n",
    "    #         df_sample['o'] = df_sample['o'] % 360\n",
    "    #     if 'dir' in df_sample.keys():\n",
    "    #         df_sample['dir'] = df_sample['dir'] + 180.0\n",
    "    #         df_sample['dir'] = df_sample['dir'] % 360\n",
    "        \n",
    "    #     frames = [df, df_sample]\n",
    "    #     combined_df = pd.concat(frames)\n",
    "    #     return combined_df\n",
    "\n",
    "    def apply_augmentation(self, df):\n",
    "        # Flipping Plays in the y direction (sideline to sideline)\n",
    "        sample_ids = np.random.choice(df.gamePlayId.unique(), int(0.5 * len(df.gamePlayId.unique())))\n",
    "        \n",
    "        # Create a sample DataFrame (explicit copy to avoid SettingWithCopyWarning)\n",
    "        df_sample = df.loc[df.gamePlayId.isin(sample_ids)].copy()\n",
    "        \n",
    "        # Modify the 'y' column\n",
    "        df_sample.loc[:, 'y'] *= -1\n",
    "    \n",
    "        # Modify 'gamePlayId' column\n",
    "        df_sample.loc[:, 'gamePlayId'] = df_sample['gamePlayId'].apply(lambda x: x + '_flipped')\n",
    "    \n",
    "        # Modify 'o' column if present\n",
    "        if 'o' in df_sample.columns:\n",
    "            df_sample.loc[:, 'o'] = (df_sample['o'] + 180.0) % 360\n",
    "    \n",
    "        # Modify 'dir' column if present\n",
    "        if 'dir' in df_sample.columns:\n",
    "            df_sample.loc[:, 'dir'] = (df_sample['dir'] + 180.0) % 360\n",
    "    \n",
    "        # Combine original and augmented DataFrames\n",
    "        combined_df = pd.concat([df, df_sample], ignore_index=True)\n",
    "    \n",
    "        return combined_df\n",
    "\n",
    "    \n",
    "    def get_situation_data(self, gamePlayId):\n",
    "        \"\"\"\n",
    "        Prepare yardline, endzone, or score data if 'endzone_info', 'play_info', \n",
    "        and/or 'score_info' is included in 'metrics' \n",
    "        \n",
    "        \"\"\"\n",
    "        gameId = int(gamePlayId[:10])\n",
    "        playId = int(gamePlayId[10:].split(\"_\")[0])#.replace(\"_flipped\",\"\").replace(\"_duplicated\", \"\"))\n",
    "\n",
    "        play_data = plays_df[(plays_df['gameId'] == gameId) & (plays_df['playId'] == playId)]\n",
    "        if len(play_data) > 1: # Handling duplicates (example- gameId: 2021110100, playId: 1267)\n",
    "            play_data = play_data.head(1)\n",
    "        \n",
    "        yards_to_go = 2 if int(play_data['yardsToGo']) == 0 else int(play_data['yardsToGo']) # 0 means 2 point conversion\n",
    "        yards_to_endzone = 100 - int(play_data['yardlineNumber']) if play_data['yardlineSide'].item() == play_data['possessionTeam'].item() else int(play_data['yardlineNumber'])\n",
    "\n",
    "        gameclock_h, gameclock_s = play_data['gameClock'].item().split(\":\")\n",
    "        time_left_half = int(gameclock_h) + int(gameclock_s)/60.0 \n",
    "        time_left_half = 1.0 if time_left_half < 1 else time_left_half\n",
    "        time_left_half = time_left_half * 2 if int(play_data['quarter']) % 2 != 0 else time_left_half\n",
    "        half_num = 1 if int(play_data['quarter']) <=2 else 2\n",
    "        down = 4 if int(play_data['down']) == 0 else int(play_data['down']) # 0 means 2 point conversion\n",
    "\n",
    "        game_data = games_df[(games_df['gameId'] == gameId)]\n",
    "        point_diff = int(play_data['preSnapHomeScore']) - int(play_data['preSnapVisitorScore'])\n",
    "        point_diff = point_diff * -1 if game_data['homeTeamAbbr'].item() != play_data['possessionTeam'].item() else point_diff\n",
    "        \n",
    "        # Combine situation data into three stats: \n",
    "        endzone_info = yards_to_endzone #/time_left_half # How much time they have to get into the endzone \n",
    "        play_info = yards_to_go #/ (5 - down) # How many downs they have to get the first down\n",
    "        score_info = point_diff * half_num / time_left_half + 1e-3 # Taking into account urgency\n",
    "        if 'endzone_info' in self.METRICS and 'play_info' in self.METRICS and 'score_info' in self.METRICS:\n",
    "            return endzone_info, play_info, score_info\n",
    "        elif 'endzone_info' in self.METRICS and 'play_info' in self.METRICS:\n",
    "            return endzone_info, play_info\n",
    "        elif 'endzone_info' in self.METRICS and 'score_info' in self.METRICS:\n",
    "            return endzone_info, score_info\n",
    "        elif 'play_info' in self.METRICS and 'score_info' in self.METRICS:\n",
    "            return play_info, score_info\n",
    "        elif 'endzone_info' in self.METRICS:\n",
    "            return [endzone_info]\n",
    "        elif 'play_info' in self.METRICS:\n",
    "            return [play_info]\n",
    "        elif 'score_info' in self.METRICS:\n",
    "            return [score_info]\n",
    "    \n",
    "    def standardize_tensor(self, tensor):\n",
    "        if self.STANDARDIZE_TYPE == 'mean':\n",
    "            channel_mean = np.mean(tensor, axis = (0,2,3)) # Get average of each metric (dim 3) over all players (dim 2) and over all batches (dim 0). Outputs shape (NUM_METRICS,)\n",
    "            channel_std = np.std(tensor, axis = (0,2,3))\n",
    "            \n",
    "            # Expand shape to use with tensor\n",
    "            channel_mean = np.tile(channel_mean, (tensor.shape[0], 1))[:,:,None,None]\n",
    "            channel_std = np.tile(channel_std, (tensor.shape[0], 1))[:,:,None,None]\n",
    "            tensor = (tensor - channel_mean)/channel_std\n",
    "        elif self.STANDARDIZE_TYPE == 'min-max':\n",
    "            channel_min = np.min(tensor, axis = (0,2,3)) # Get min of each metric (dim 3) over all players (dim 2) and over all batches (dim 0). Outputs shape (NUM_METRICS,)\n",
    "            channel_max = np.max(tensor, axis = (0,2,3))\n",
    "            \n",
    "            # Expand shape to use with tensor\n",
    "            channel_min = np.tile(channel_min, (tensor.shape[0], 1))[:,:,None,None]\n",
    "            channel_max = np.tile(channel_max, (tensor.shape[0], 1))[:,:,None,None]\n",
    "            tensor = (tensor - channel_min) / (channel_max - channel_min)\n",
    "        return tensor\n",
    "    \n",
    "    def get_dataset(self, grouped):\n",
    "        tensor           = np.zeros([self.NUM_PLAYS, self.NUM_DEFENSIVE, self.NUM_OFFENSIVE, self.NUM_METRICS]) \n",
    "        labels           = np.zeros([self.NUM_PLAYS, self.NUM_DEFENSIVE]).astype(int)\n",
    "        playerIds        = np.zeros([self.NUM_PLAYS, self.NUM_DEFENSIVE])\n",
    "        playerPosLinedUp = np.zeros([self.NUM_PLAYS, self.NUM_DEFENSIVE]).astype(str)\n",
    "        playerPos        = np.zeros([self.NUM_PLAYS, self.NUM_DEFENSIVE]).astype(str)\n",
    "        playerBlocked    = np.zeros([self.NUM_PLAYS, self.NUM_DEFENSIVE]).astype(int)\n",
    "        playerHurries    = np.zeros([self.NUM_PLAYS, self.NUM_DEFENSIVE]).astype(int)\n",
    "        playerHits       = np.zeros([self.NUM_PLAYS, self.NUM_DEFENSIVE]).astype(int)\n",
    "        playerSacks      = np.zeros([self.NUM_PLAYS, self.NUM_DEFENSIVE]).astype(int)\n",
    "        playIds          = np.zeros(self.NUM_PLAYS).astype(str)\n",
    "        blitzIds         = np.zeros(self.NUM_PLAYS).astype(str)\n",
    "        \n",
    "        i = 0\n",
    "        block_type_list = ['SW', 'PP', 'CL', 'PA', 'PU', 'CH', 'NB', 'UP', 'SR', 'PR']#[l for l in self.presnap_df['pff_blockType'].unique() if l not in ['PT', 'BH', np.nan]]\n",
    "        for playid, data in grouped:\n",
    "            # Location of the center is used as the ball location approx\n",
    "            center_pos = data[data['pff_positionLinedUp'] == 'C']\n",
    "            center_x = center_pos.x.item()\n",
    "            center_y = center_pos.y.item()\n",
    "            \n",
    "            # Make every play the same direction\n",
    "            FLIP_DIR = -1 if data['playDirection'].values[0] == 'left' else 1\n",
    "            data['x_to_ball'] = FLIP_DIR * (data.x - center_x) \n",
    "            data['y_to_ball'] = FLIP_DIR * (data.y - center_y)\n",
    "            data['x_to_ball'] *= data['IsOnDefense'] # Doesn't matter close offensive players are to the LOS\n",
    "            \n",
    "            if FLIP_DIR == -1:\n",
    "                data['o'] = data['o'] + 180.0\n",
    "                data['o'] = data['o'] % 360\n",
    "                data['dir'] = data['dir'] + 180.0\n",
    "                data['dir'] = data['dir'] % 360\n",
    "            \n",
    "            data['positionKey'] = data.apply(lambda row: self.get_position_key(row) if row.IsOnDefense else 0, axis=1)\n",
    "            \n",
    "            # Keep track of which players are blocked on the play for evaluation while not considering PT or BH blocks (indicates the player they are blocking were not their initial assigned blocker/job)\n",
    "            data.loc[data.loc[data.pff_blockType.isin(block_type_list).index, 'nflId'].isin(data.pff_nflIdBlockedPlayer), 'isBlocked'] = 1\n",
    "            data['isBlocked'] = data['isBlocked'].astype(int)\n",
    "\n",
    "            pos_not_included = [m for m in self.EXCLUDED_POS if m not in data['pff_positionLinedUp'].values]\n",
    "            for m in pos_not_included:\n",
    "                # If there is not a player in the specified LT/RT/RG/LG position, then remove the pass blocker closest to the center (not a perfect solution but only needed for a couple plays)\n",
    "                print(\"No specified %s, assigning random pass blocker to this position...\" % m)\n",
    "                ind_to_change = data[(data.pff_role == 'Pass Block') & (~data['pff_positionLinedUp'].isin(self.EXCLUDED_POS))].sort_values('x_to_ball').index[0]\n",
    "                data.loc[ind_to_change, 'pff_positionLinedUp'] = m\n",
    "            \n",
    "            data = data.drop(data[data['pff_positionLinedUp'].isin(self.EXCLUDED_POS)].index)\n",
    "            \n",
    "            if self.order == 'left-to-right':\n",
    "                data = data.sort_values(by = ['IsOnDefense', 'y_to_ball'], ascending=[False, True])\n",
    "            elif self.order == 'top-to-bottom':\n",
    "                data = data.sort_values(by = ['IsOnDefense', 'x_to_ball'], ascending=[False, False])\n",
    "            elif self.order == 'positionKey':\n",
    "                data = data.sort_values(by = ['IsOnDefense', 'positionKey', 'x_to_ball'], ascending=[False, True, True])\n",
    "            elif self.order == 'shuffle':\n",
    "                data = data.sample(frac = 1)\n",
    "            \n",
    "        \n",
    "            data.index = data.nflId\n",
    "            offense_ids = data[~data.IsOnDefense.astype(bool)].index\n",
    "            defense_ids = data[data.IsOnDefense.astype(bool)].index\n",
    "            \n",
    "            info_stats = self.get_situation_data(playid)\n",
    "            \n",
    "            all_off_data = data.loc[offense_ids, ['x_to_ball', 'y_to_ball']].values\n",
    "\n",
    "            \n",
    "            def_metrics = data.loc[defense_ids, self.METRICS[:len(self.METRICS) - len(self.INFO_METRICS)]].values # Get defense metrics (x to ball, y to ball, and o/dir/a/etc if specified)\n",
    "            tensor[i,:,:,:2] = -1*all_off_data + np.array([def_metrics[:,0], def_metrics[:,1]]).transpose()[:,None] # Subtract offensive player location from each def player location\n",
    "\n",
    "            tensor[i,:,:,2:2+def_metrics.shape[1]] = def_metrics[:,None,:]\n",
    "            \n",
    "            if len(self.INFO_METRICS) > 0:\n",
    "                    # If we are considering situation (down, quarter, yardline) info\n",
    "                    for m, metric in enumerate(info_stats):\n",
    "                        if 'play_info' in self.INFO_METRICS or 'endzone_info' in self.INFO_METRICS:\n",
    "                            if self.INFO_METRICS.index('play_info') == m or self.INFO_METRICS.index('endzone_info') == m:\n",
    "                                metric -= data.loc[defense_ids, 'x_to_ball'].values[:, None]\n",
    "                                #metric += abs(data.loc[offense_ids, 'x_to_ball'])\n",
    "                        tensor[i,:,:,2+def_metrics.shape[1] + m] = metric#[:,None,:]\n",
    "            \n",
    "            labels[i] = data.loc[defense_ids, 'passRusher'].values\n",
    "            playIds[i] = playid\n",
    "            blitzIds[i] = data['blitzId'].values[0] # Used for sampling\n",
    "            playerBlocked[i] = data.loc[defense_ids, 'isBlocked'].values # Used for eval. Todo: only add these for evaluation and visualization, not needed for testing \n",
    "            playerHits[i] = data.loc[defense_ids, 'pff_hit'].values \n",
    "            playerHurries[i] = data.loc[defense_ids, 'pff_hurry'].values\n",
    "            playerSacks[i] = data.loc[defense_ids, 'pff_sack'].values\n",
    "            playerIds[i] = defense_ids\n",
    "            playerPosLinedUp[i] = data.loc[defense_ids, 'pff_positionLinedUp'].values\n",
    "            playerPos[i] = data.loc[defense_ids, 'officialPosition'].values\n",
    "            i+=1\n",
    "\n",
    "        tensor = tensor.transpose((0,3,1,2)) # PyTorch have the \"channels\" or \"metrics\" in 2nd dim (because this is \"in_features\" in Conv2d)\n",
    "\n",
    "        if self.STANDARDIZE_TYPE is not None:\n",
    "            tensor = self.standardize_tensor(tensor)\n",
    "        self.tensor = tensor\n",
    "        self.labels = labels\n",
    "        self.playIds = playIds\n",
    "        self.blitzIds = blitzIds\n",
    "        self.playerIds = playerIds\n",
    "        self.playerPosLinedUp = playerPosLinedUp\n",
    "        self.playerPos = playerPos\n",
    "        self.playerBlocked = playerBlocked\n",
    "        self.playerHits = playerHits\n",
    "        self.playerHurries = playerHurries\n",
    "        self.playerSacks = playerSacks\n",
    "        \n",
    "    def collate(self, batch):\n",
    "        # Use custom collate function to also batch together labels, playerIds, etc. and be able to plot predictions (PyTorch's collate function will only batch the tensor) \n",
    "        new_batch = {}\n",
    "        tensors = []\n",
    "        labels = []\n",
    "        for i in range(0, len(batch)):\n",
    "            tensors.append(torch.tensor(batch[i]['data']))\n",
    "            labels.append(batch[i]['labels'])\n",
    "        new_batch['data'] = torch.stack(tensors)\n",
    "        new_batch['labels'] = labels\n",
    "        return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3028043-784a-4bdc-9e75-21c96c67b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DEFINE MODEL #################\n",
    "\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class Conv2D(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, kernel_size, stride = 1, pad = 0):    \n",
    "        super(Conv2D, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_features, out_features, kernel_size = kernel_size, stride = stride, padding = pad, bias = False)\n",
    "        #self.conv.weight.data.normal_(0.0, 0.01)\n",
    "        self.bn = torch.nn.BatchNorm2d(out_features)\n",
    "        #self.bn.bias.data.fill_(2.7)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.relu = torch.nn.LeakyReLU() # Add inplace=True?\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out) # Leaky RELU?\n",
    "        out = self.dropout(out) \n",
    "        return out\n",
    "\n",
    "class FCLayer(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, use_layernorm = False, use_bn = False, use_dropout = False):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.use_ln = use_layernorm\n",
    "        self.use_bn = use_bn\n",
    "        self.use_dropout = use_dropout\n",
    "        \n",
    "        self.fc = torch.nn.Linear(in_features, out_features)\n",
    "        self.relu = torch.nn.LeakyReLU()\n",
    "        self.bn = torch.nn.BatchNorm1d(out_features)\n",
    "        self.ln = torch.nn.LayerNorm(out_features)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        \n",
    "        #if use_layernorm:\n",
    "        #self.fc.weight.data.fill_(-5.0)\n",
    "        #self.bn.bias.data.fill_(0.0)\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn(out) if self.use_bn else out\n",
    "        out = self.ln(out) if self.use_ln else out\n",
    "        out = self.dropout(out) if self.use_dropout else out\n",
    "        return out  \n",
    "\n",
    "class PassRushNN(torch.nn.Module):\n",
    "    def __init__(self, in_features, num_offensive, num_defensive):\n",
    "        super().__init__()\n",
    "        f1 = 128\n",
    "        f2 = 160\n",
    "        f3 = 96\n",
    "        flast = 256\n",
    "        \n",
    "        # Gathering Features on the offensive players\n",
    "        self.conv1 = Conv2D(in_features, f1, kernel_size=(1,1), stride=1, pad = 0)\n",
    "        #self.conv15 = Conv2D(f1, f1, kernel_size=(3,3), stride=(1,1), pad = (1,1))\n",
    "        self.conv2 = Conv2D(f1, f2, kernel_size=(3,3), stride=1, pad = (1,0))\n",
    "        self.conv3 = Conv2D(f2, f1, kernel_size=(1, num_offensive), stride=1, pad = 1)\n",
    "        self.pool1 = torch.nn.AdaptiveAvgPool2d((num_defensive, 1)) # Defenders avg distance to all offense (avg array horizontally). If vertically, it's avg distance of defenders to an offensive player\n",
    "\n",
    "        # Gathering Features on the defensive players\n",
    "        self.bn = torch.nn.BatchNorm2d(f1)\n",
    "        self.conv4 = Conv2D(f1, f2, kernel_size=(1, 1), stride=1, pad = 1)\n",
    "        #self.conv45 = Conv2D(f2, f2, kernel_size=(2, 2), stride=(1,1), pad = (0,0))\n",
    "        self.conv5 = Conv2D(f2, f3, kernel_size=(3, 1), stride=1, pad = (1,0))\n",
    "        self.conv6 = Conv2D(f3, f3, kernel_size=(num_offensive, 1), stride=1, pad = (1,0))\n",
    "        self.pool2 = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = FCLayer(f3, flast, use_layernorm = True, use_dropout=True)\n",
    "        \n",
    "        self.fc_final = torch.nn.Linear(flast, num_defensive)\n",
    "        \n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss(reduction = \"mean\", pos_weight = torch.tensor([1.75])) # pos_weight > 1 penalizes FN more, < 1 penalizes FP more\n",
    "        #self._initialize_weights()\n",
    "    def _initialize_weights(self):\n",
    "        with torch.no_grad():\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, torch.nn.Conv2d):\n",
    "                    torch.nn.init.xavier_uniform_(m.weight)\n",
    "                    if m.bias is not None:\n",
    "                        torch.nn.init.zeros_(m.bias)\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x_ = self.conv2(x)\n",
    "        \n",
    "        x = self.conv3(x_) # torch.Size([bs, f1, 11, 10])\n",
    "        x = self.pool1(x)  # torch.Size([bs, f1, 1, 11])\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x) # torch.Size([bs, f3, 1, 11]) \n",
    "        x = self.pool2(x) # torch.Size([bs, f3, 1, 1])\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc_final(x)\n",
    "        return x\n",
    "    \n",
    "    def loss_func(self, pred, true):\n",
    "        loss = self.loss_fn(pred, true)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5207cf-275f-457f-9ee8-e2fffe3c8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Prepare Data for Training: ESTIMATED TIME ~7.5 minutes ###################\n",
    "order = 'left-to-right'# 'positionKey', 'left-to-right', 'top-to-bottom', or 'shuffle'\n",
    "standardize_type = None # 'min-max', 'mean', or None\n",
    "metrics = ['x_to_ball', 'y_to_ball', 'positionKey'] # 'x/y_to_ball' can be used along with 'o', 'dir', 'positionKey', 'endzone_info', 'play_info', 'score_info'\n",
    "excluded_pos_list = ['C','LG','RG']\n",
    "trainData = BlitzDataset(presnap_df_train, excluded_pos_list = excluded_pos_list, ratio_use = 1.0, metrics = metrics, standardize_type = standardize_type, order = order)\n",
    "validData = BlitzDataset(presnap_df_val, excluded_pos_list = excluded_pos_list, ratio_use=1.0, metrics = metrics, standardize_type = standardize_type, order = order)\n",
    "trainDataloader = DataLoader(trainData, batch_size = 64, shuffle = True, collate_fn = trainData.collate) # sampler = ImbalancedDatasetSampler(trainData)\n",
    "valDataloader = DataLoader(validData, batch_size = 64, shuffle = False, collate_fn = validData.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22195d8a-a8f6-4cdf-8682-d7d025066659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, train_dataloader, val_dataloader, lr = 1e-3, gamma = 1.0, weight_decay = 5e-5, num_epochs = 300, SAVE_WEIGHTS = False):\n",
    "    \n",
    "        self.num_epochs = num_epochs\n",
    "        self.SAVE_WEIGHTS = SAVE_WEIGHTS\n",
    "\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "\n",
    "        self.model = PassRushNN(trainData.NUM_METRICS, trainData.NUM_OFFENSIVE, validData.NUM_DEFENSIVE).float()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = lr)\n",
    "\n",
    "        self.min_val_loss = 1e9\n",
    "        \n",
    "        self.model.train()\n",
    "        self.best_model = None\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=len(self.train_dataloader), gamma=gamma)\n",
    "        \n",
    "        self.session_datetime = datetime.datetime.today().strftime(\"%Y-%m-%d-%H-%M-%S\") # For saving weights\n",
    "        \n",
    "    def train_epoch(self, cur_epoch = 0):\n",
    "        self.model.train()\n",
    "        epoch_train_loss = 0\n",
    "        start_time = time.time()\n",
    "        for idx, sample in enumerate(self.train_dataloader):\n",
    "            pred = self.model(sample['data'].float())\n",
    "            labels = sample['labels']\n",
    "            labels = torch.tensor(np.stack([l['isRusher'] for l in sample['labels']])).float()\n",
    "            batch_loss = self.model.loss_func(pred,labels)\n",
    "            epoch_train_loss += batch_loss.item()\n",
    "            self.optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            if idx % 250 == 0 and idx != 0:\n",
    "                time_per_step = (time.time() - start_time)/idx\n",
    "                print(\"Epoch [%i/%i], Step [%i/%i], Loss: %.5f, Avg Step Time: %.3f\" % (cur_epoch, self.num_epochs, idx, len(self.train_dataloader), batch_loss.item(), time_per_step))\n",
    "        \n",
    "        epoch_train_loss /= len(self.train_dataloader)\n",
    "        print(\"Train Loss Avg: \", epoch_train_loss)\n",
    "\n",
    "    \n",
    "    def get_epoch_val_loss(self, cur_epoch = 0): \n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "\n",
    "            epoch_val_loss = 0\n",
    "            TP_total = 0\n",
    "            TN_total = 0\n",
    "            FP_total = 0\n",
    "            FN_total = 0\n",
    "            for idx, sample in enumerate(self.val_dataloader):\n",
    "                pred = self.model(sample['data'].float())\n",
    "                labels = sample['labels']\n",
    "                labels = torch.tensor(np.stack([l['isRusher'] for l in sample['labels']])).float()\n",
    "                val_loss = self.model.loss_func(pred,labels)\n",
    "                epoch_val_loss += val_loss.item()\n",
    "                pred = torch.nn.functional.sigmoid(pred)\n",
    "                TP_total += np.sum(np.logical_and(np.array(pred) >= 0.5, np.array(labels) == 1))\n",
    "                TN_total += np.sum(np.logical_and(np.array(pred) <  0.5, np.array(labels) == 0))\n",
    "                FP_total += np.sum(np.logical_and(np.array(pred) >= 0.5, np.array(labels) == 0))\n",
    "                FN_total += np.sum(np.logical_and(np.array(pred) <  0.5, np.array(labels) == 1))\n",
    "            \n",
    "            epoch_val_loss /= len(self.val_dataloader)\n",
    "            \n",
    "            RECALL    = TP_total / (max(TP_total + FN_total, 1)) # Of all blitzers, what percentage were predicted to be blitzers\n",
    "            PRECISION = TP_total / (max(TP_total + FP_total, 1)) # Of all predicted blitzers, what percentage are actually blitzers?\n",
    "            ACCURACY  = (TP_total + TN_total) / (TP_total + TN_total + FP_total + FN_total)\n",
    "\n",
    "            print(\"val loss: \", epoch_val_loss)\n",
    "            if epoch_val_loss < self.min_val_loss:\n",
    "                self.min_val_loss = epoch_val_loss\n",
    "                print(\"NEW MINIMUM VALID LOSS %0.4f\" % self.min_val_loss)\n",
    "                print(\"TP: %i\\nTN: %i\\nFP: %i\\nFN: %i\" % (TP_total, TN_total, FP_total, FN_total))\n",
    "                print(\"RECALL: %i%%\\nPRECISION: %i%%\\nACCURACY: %i%%\\n\" % (RECALL * 100, PRECISION * 100, ACCURACY * 100))\n",
    "                self.best_model = self.model\n",
    "                print(\"Prediction Example: \", pred[0])\n",
    "                print(\"Example's Labels: \", labels[0])\n",
    "                \n",
    "                if self.SAVE_WEIGHTS:\n",
    "                    fname = \"blitz_prob_%s_%0.3f\" % (self.session_datetime, epoch_val_loss)\n",
    "                    if not os.path.isdir(\"./weights\"):\n",
    "                        os.makedirs(\"./weights\")\n",
    "                    if len(glob.glob(\"./weights/blitz_prob_%s_*\" % (self.session_datetime))) == 0:\n",
    "                        os.makedirs(\"./weights/%s\" % fname)\n",
    "                    else:\n",
    "                        fold = glob.glob(\"./weights/blitz_prob_%s_*\" % (self.session_datetime))[0]\n",
    "                        os.rename(fold, \"./weights/\" + fname)\n",
    "                        \n",
    "                        \n",
    "                    fpath = os.path.join(\"./weights\", fname)\n",
    "                    text = \"\\n\".join([\"%s: %s\" % (n, trainData.__dict__[n]) for n in ['order', 'STANDARDIZE_TYPE', 'EXCLUDED_POS', 'NUM_PLAYS', 'NUM_OFFENSIVE', 'NUM_DEFENSIVE', 'METRICS', 'NUM_METRICS', 'pos_keys']])\n",
    "                    text += \"\\nNUM EPOCHS: %i\\n\" % cur_epoch\n",
    "                    text += \"TP: %i\\nTN: %i\\nFP: %i\\nFN: %i\\n\" % (TP_total, TN_total, FP_total, FN_total)\n",
    "                    text += \"RECALL: %i%%\\nPRECISION: %i%%\\nACCURACY: %i%%\\n\" % (RECALL * 100, PRECISION * 100, ACCURACY * 100)\n",
    "                    text += \"\\nOptimizer: %s\\n\" % self.optimizer\n",
    "                    text += \"\\nModel: %s\\n\" % self.model#(self.model.conv1, self.model.conv2, self.model.pool1, self.model.pool2)\n",
    "                    \n",
    "                    with open(fpath + \"/info.txt\", 'w') as f:\n",
    "                        f.write(text)\n",
    "                    torch.save(self.best_model, fpath + \"/torch_weights\")\n",
    "                    \n",
    "    def run_once(self):\n",
    "        for cur_epoch in range(self.num_epochs):\n",
    "            self.train_epoch(cur_epoch)\n",
    "            self.get_epoch_val_loss(cur_epoch)\n",
    "\n",
    "trainer = Trainer(trainDataloader, valDataloader, lr = 1e-3, gamma = 1.0, num_epochs = 40, SAVE_WEIGHTS = False)\n",
    "trainer.run_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60e7f6-24bd-4ac0-b538-9764135d93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ VISUALIZATION OF PERFORMANCE ################\n",
    "def create_football_field(ax, linenumbers=True,\n",
    "                            endzones=True,\n",
    "                            highlight_line=False,\n",
    "                            highlight_line_number=55,\n",
    "                            highlight_first_down_line=False,\n",
    "                            yards_to_go=10,\n",
    "                            highlighted_name='Line of Scrimmage',\n",
    "                            fifty_is_los=False,\n",
    "                            figsize=(12, 5.33)):\n",
    "\n",
    "    ypix = figsize[0]*10\n",
    "    xpix = figsize[1]*10\n",
    "\n",
    "    rect = patches.Rectangle((0, 0), xpix, ypix, linewidth=0.1,\n",
    "                                edgecolor='r', facecolor='darkgreen', zorder=0)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    yardlines_x = [0, 0, xpix, xpix, 0, 0, xpix, xpix, 0, 0, xpix, xpix, 0, 0, xpix,\n",
    "            xpix, 0, 0, xpix, xpix, 0, 0, xpix, xpix, xpix, 0, 0, xpix]\n",
    "    yardlines_y = [10, 10, 10, 20, 20, 30, 30, 40, 40, 50, 50, 60, 60, 70, 70, 80,\n",
    "            80, 90, 90, 100, 100, 110, 110, 120, 0, 0, 120, 120]\n",
    "    ax.plot(yardlines_x, [y  * ypix/120 for y in yardlines_y], color='white')\n",
    "\n",
    "    if fifty_is_los:\n",
    "        ax.plot([0, xpix], [60, 60], color='gold')\n",
    "        ax.text(50, 62, '<- Player Yardline at Snap', color='gold')\n",
    "    \n",
    "    # Endzones\n",
    "    if endzones:\n",
    "        ez1 = patches.Rectangle((0, 0), xpix, ypix/12,\n",
    "                                linewidth=0.1,\n",
    "                                edgecolor='r',\n",
    "                                facecolor='blue',\n",
    "                                alpha=0.2,\n",
    "                                zorder=0)\n",
    "        ez2 = patches.Rectangle((0, ypix - ypix/12), xpix, ypix,\n",
    "                                linewidth=0.1,\n",
    "                                edgecolor='r',\n",
    "                                facecolor='blue',\n",
    "                                alpha=0.2,\n",
    "                                zorder=0)\n",
    "        \n",
    "    if linenumbers:\n",
    "        for i in range(20, 110, 10):\n",
    "            num = i\n",
    "            if i > 50:\n",
    "                num = 120 - i\n",
    "            ax.text(xpix/12, i * ypix/120 - ypix/280, str(num - 10),\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    fontsize=ypix/12, fontname='serif',\n",
    "                    color='white', rotation = 90, clip_on = True)\n",
    "            ax.text(xpix - xpix/12, i  * ypix/120 + ypix/280, str(num - 10),\n",
    "                    horizontalalignment='center',\n",
    "                    fontsize=ypix/12,  fontname='serif',\n",
    "                    color='white', rotation=90, clip_on = True)\n",
    "\n",
    "    if endzones:\n",
    "        #hash_range = range(ypix - 1, ypix - int(ypix/10))\n",
    "        hash_range = range(int(ypix/12), int(ypix) - int(ypix/12),3)\n",
    "        hash_range = np.linspace(int(ypix/12), int(ypix) - int(ypix/12),100)\n",
    "    else:\n",
    "        hash_range = range(1, ypix/12)\n",
    "\n",
    "    # Hash Marks 9.25 ft (6.167 yards or 0.125 the width) on either side of the middle of the field, and on the edges of the field\n",
    "    for x in hash_range:\n",
    "        ax.plot([0.0, xpix/100], [x, x], color='white')\n",
    "        ax.plot([xpix - xpix/100, xpix], [x, x], color='white')\n",
    "        ax.plot([xpix/2 - xpix*0.125 - xpix/100, xpix/2 - xpix*0.125 + xpix/100], [x, x], color='white')\n",
    "        ax.plot([xpix/2 + xpix*0.125 - xpix/100, xpix/2 + xpix*0.125 + xpix/100], [x, x], color='white')\n",
    "\n",
    "    if highlight_line:\n",
    "        hl = highlight_line_number * ypix/120 + ypix/12\n",
    "        ax.plot([0, xpix], [hl, hl], color='black')\n",
    "    \n",
    "    if highlight_first_down_line:\n",
    "        fl = hl + yards_to_go * ypix/120\n",
    "        ax.plot([0, xpix], [fl, fl], color='yellow')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447bf007-6867-4380-8d8f-355584c4e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    # Assumes premerged scouting_df and tracking_df with the \"frameId\" == 1 and playId and gameId combined to gamePlayIds, may work with tracking_df and frameId == 1?\n",
    "    def __init__(self, df_presnap, df_presnap_val, which_model = 'last'):\n",
    "        self.val_dataloader = None\n",
    "        weights_dir = glob.glob(\"./weights/blitz_prob*\")\n",
    "        if which_model == 'best' and len(weights_dir) > 0:\n",
    "            min_loss = np.min([float(file.split(\"_\")[-1]) for file in weights_dir])\n",
    "            for session in weights_dir:\n",
    "                if str(min_loss) in session:\n",
    "                    print(\"Using %s weights...\" % session)\n",
    "                    model_ = torch.load(session + \"/torch_weights\")\n",
    "                    txt_path = session + \"/info.txt\"\n",
    "                    with open(session + \"/info.txt\", 'r') as f:\n",
    "                        for line in f.readlines():\n",
    "                            if 'METRICS: [' in line:\n",
    "                                metrics_ = ast.literal_eval(line.split(\": \")[1])\n",
    "                            elif 'EXCLUDED_POS:' in line:\n",
    "                                excluded_pos_ = ast.literal_eval(line.split(\": \")[1])\n",
    "                            elif 'order:' in line:\n",
    "                                order_ = line.replace(\"\\n\",\"\").split(\": \")[1]\n",
    "                            elif 'STANDARDIZE_TYPE:' in line:\n",
    "                                standardize_type_ = line.replace(\"\\n\",\"\").split(\": \")[1]\n",
    "                            \n",
    "        elif 'blitz_prob' in which_model:\n",
    "            model_ = torch.load(\"./weights/%s/torch_weights\" % which_model).float()\n",
    "            with open(\"./weights/%s/info.txt\" % which_model, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    if 'METRICS: [' in line:\n",
    "                        metrics_ = ast.literal_eval(line.split(\": \")[1])\n",
    "                    elif 'EXCLUDED_POS:' in line:\n",
    "                        excluded_pos_ = ast.literal_eval(line.split(\": \")[1])\n",
    "                    elif 'order:' in line:\n",
    "                        order_ = line.replace(\"\\n\",\"\").split(\": \")[1]\n",
    "                    elif 'STANDARDIZE_TYPE:' in line:\n",
    "                        standardize_type_ = line.replace(\"\\n\",\"\").split(\": \")[1]\n",
    "\n",
    "        else: \n",
    "            model_ = trainer.best_model\n",
    "            metrics_ = metrics\n",
    "            excluded_pos_ = excluded_pos_list\n",
    "            order_ = order\n",
    "            standardize_type_ = standardize_type\n",
    "            self.val_dataloader = valDataloader\n",
    "            \n",
    "        \n",
    "        self.metrics = metrics_\n",
    "        self.excluded_pos = excluded_pos_\n",
    "        self.order = order_\n",
    "        self.standardize_type = standardize_type_\n",
    "        self.model = model_\n",
    "        self.model.eval()\n",
    "        self.presnap_df = df_presnap\n",
    "        self.presnap_df_val = df_presnap_val\n",
    "        self.testData = None\n",
    "        self.pred = None\n",
    "        self.positive_thresh = 0.7\n",
    "        self.which_model = which_model\n",
    "        \n",
    "    def analyze_a_play(self, gameId, playId, frameId = 1):\n",
    "        play_df = get_play_df(gameId = gameId, playId = playId, frames = frameId) \n",
    "        play_labels = BlitzDataset(play_df, excluded_pos_list = self.excluded_pos, metrics=self.metrics, order = self.order, standardize_type=self.standardize_type, training = False)\n",
    "        \n",
    "        if frameId == 'all':\n",
    "            max_frame = play_df.frameId.max()\n",
    "            ball_snap_frame = 6\n",
    "            play_pred = self.model(torch.FloatTensor(play_labels.tensor[0:ball_snap_frame])) # Ball is snapped on frame 6 (TODO: automate incase this changes)\n",
    "            play_pred = torch.nn.functional.sigmoid(play_pred) if isinstance(self.model.loss_fn, torch.nn.BCEWithLogitsLoss ) else self.pred\n",
    "            pred_temp = torch.zeros(max_frame, play_pred.shape[1])\n",
    "            pred_temp[:play_pred.shape[0]] = play_pred\n",
    "            pred_temp[play_pred.shape[0]:] = play_pred[ball_snap_frame - 1]\n",
    "            for i in range(ball_snap_frame, max_frame):\n",
    "                sorted_id_ind = [np.where(nflId == play_labels.playerIds[ball_snap_frame - 1])[0].item() for nflId in play_labels.playerIds[i]]\n",
    "   \n",
    "                pred_temp[i] = pred_temp[i][sorted_id_ind]\n",
    "            play_pred = pred_temp\n",
    "        else:\n",
    "            play_pred = self.model(torch.FloatTensor(play_labels.tensor)) \n",
    "            play_pred = torch.nn.functional.sigmoid(play_pred) if isinstance(self.model.loss_fn, torch.nn.BCEWithLogitsLoss ) else self.pred\n",
    "        return play_df, play_labels, play_pred\n",
    "    \n",
    "    def get_blocking_data(self, df):\n",
    "        # See who blocked who on the play\n",
    "        blocking_df = df[df['pff_role'] == 'Pass Block'].reset_index()\n",
    "        blocked_df = df[(df.nflId.isin(blocking_df.pff_nflIdBlockedPlayer))].reset_index()\n",
    "        \n",
    "        \n",
    "        blocking_df['pff_nflIdBlockedPlayer'] = blocking_df['pff_nflIdBlockedPlayer'].fillna(0)\n",
    "        blocked_df['pff_nflIdBlockedPlayer'] = blocked_df['pff_nflIdBlockedPlayer'].fillna(0)\n",
    "        #blocking_df['pff_nflIdBlockedPlayer'] = blocking_df['pff_nflIdBlockedPlayer'].astype(int)\n",
    "        #blocked_df['pff_nflIdBlockedPlayer'] = blocked_df['pff_nflIdBlockedPlayer'].astype(int)\n",
    "        blocking_df['jerseyBlockedPlayer'] = blocking_df.apply(lambda row: np.nan if len(blocked_df[(blocked_df.nflId == row.pff_nflIdBlockedPlayer)]['jerseyNumber'].values) == 0 else blocked_df[(blocked_df.nflId == row.pff_nflIdBlockedPlayer)]['jerseyNumber'].values[0], axis = 1)\n",
    "        blocking_df['xBlockedPlayer']      = blocking_df.apply(lambda row: np.nan if len(blocked_df[(blocked_df.nflId == row.pff_nflIdBlockedPlayer)]['x'].values) == 0 else blocked_df[(blocked_df.nflId == row.pff_nflIdBlockedPlayer)]['x'].values[0], axis = 1)\n",
    "        blocking_df['yBlockedPlayer']      = blocking_df.apply(lambda row: np.nan if len(blocked_df[(blocked_df.nflId == row.pff_nflIdBlockedPlayer)]['y'].values) == 0 else blocked_df[(blocked_df.nflId == row.pff_nflIdBlockedPlayer)]['y'].values[0], axis = 1)\n",
    "        return blocking_df\n",
    "    \n",
    "    def get_yardline_info(self, df, gameId, playId):\n",
    "        play_info = plays_df[(plays_df['playId'] == playId) & (plays_df['gameId'] == gameId)]\n",
    "        game_info = games_df[games_df['gameId'] == gameId]\n",
    "        # TODO: clean this up\n",
    "        home_team    = game_info['homeTeamAbbr'].values[0]\n",
    "        home_info = df[(df['team'] == home_team)]\n",
    "        \n",
    "        yardlineNumber = play_info['yardlineNumber'].item()\n",
    "        yardsToGo      = play_info['yardsToGo'].item()\n",
    "        absoluteYardlineNumber = play_info['absoluteYardlineNumber'].item() - 10\n",
    "        playDir = home_info.sample(1)['playDirection'].item()\n",
    "\n",
    "        if (absoluteYardlineNumber > 50):\n",
    "            yardlineNumber = 100 - yardlineNumber\n",
    "        if (absoluteYardlineNumber <= 50):\n",
    "            yardlineNumber = yardlineNumber\n",
    "            \n",
    "        if (playDir == 'left'):\n",
    "            yardsToGo = -yardsToGo\n",
    "        else:\n",
    "            yardsToGo = yardsToGo\n",
    "        return yardlineNumber, yardsToGo\n",
    "    \n",
    "    def draw_play(self, gameId, playId, df, labels, pred, frameId = 1, blocking_df = None, figsize = (5.33, 12), draw_animation = False, ax = None):\n",
    "        patch = []\n",
    "        play_info = plays_df[(plays_df['playId'] == playId) & (plays_df['gameId'] == gameId)]\n",
    "        game_info = games_df[games_df['gameId'] == gameId]\n",
    "        \n",
    "        home_team    = game_info['homeTeamAbbr'].values[0]\n",
    "        home_info = df[(df['team'] == home_team)]\n",
    "        play_dir = home_info.sample(1)['playDirection'].item()\n",
    "\n",
    "        if not draw_animation:\n",
    "            yardlineNumber, yardsToGo = self.get_yardline_info(df, gameId, playId)\n",
    "            figsize = (30, 20)\n",
    "            \n",
    "            fig = plt.figure(figsize = figsize[::-1])\n",
    "            ax = fig.gca()\n",
    "            ax.set_aspect('equal', 'box')\n",
    "            fig.patch.set_visible(False)\n",
    "            plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "            plt.margins(0, 0)\n",
    "            ax.axis('off')\n",
    "    \n",
    "            ax = create_football_field(ax, highlight_line=True, highlight_line_number=yardlineNumber, highlight_first_down_line=True, yards_to_go=yardsToGo, figsize = figsize)\n",
    "            \n",
    "        ypix = figsize[0]*10\n",
    "        xpix = figsize[1]*10\n",
    "        playDesc = play_info['playDescription'].item()\n",
    "        if frameId == 1:\n",
    "            ax.set_title(\"%s: %s %s: %s \\n GameId: %s PlayId: %s\\nDown: %s Quarter: %s Time: %s\\nResult: %s\" % (game_info['homeTeamAbbr'].item(), play_info['preSnapHomeScore'].item(), game_info['visitorTeamAbbr'].item(), play_info['preSnapVisitorScore'].item(), gameId, playId, play_info['down'].item(), play_info['quarter'].item(), play_info['gameClock'].item(), play_info['playDescription'].item()), fontsize = 15, clip_on = False) \n",
    "\n",
    "        min_x = 1e9\n",
    "        max_x = 0\n",
    "        #total_x = 0\n",
    "        #total_y = 0\n",
    "        #total_prob = 0\n",
    "        for ind, row in df.iterrows():\n",
    "            y = row.y * xpix/53.3\n",
    "            x = row.x * ypix/120\n",
    "            b_home = row.IsOnDefense\n",
    "            #color = \"black\" if not row.IsOnDefense else \"green\"\n",
    "            if row.IsOnDefense:\n",
    "                color = \"gray\"\n",
    "                fcolor = \"black\"\n",
    "                bcolor = \"white\"\n",
    "                playerInd = np.where(labels.playerIds[frameId - 1] == row.nflId)[0][0]\n",
    "                if np.isnan(pred[0][playerInd].item()):\n",
    "                    pred[0][playerInd] = torch.tensor(1.1)\n",
    "                \n",
    "                #total_x += (x * pred[frameId - 1][playerInd].item())\n",
    "                #total_y += (y * pred[frameId - 1][playerInd].item())\n",
    "                #total_prob += pred[0][playerInd].item()\n",
    "                if row.passRusher:\n",
    "                    color = \"orange\"\n",
    "                    if int(pred[0][playerInd].item() * 100) >= self.positive_thresh * 100:\n",
    "                        fcolor = \"black\"\n",
    "                    elif int(pred[0][playerInd].item() * 100) < self.positive_thresh * 100:\n",
    "                        fcolor = \"firebrick\"\n",
    "                    if row.pff_hit or row.pff_hurry or row.pff_sack:\n",
    "                        bcolor = \"firebrick\"\n",
    "                elif int(pred[0][playerInd].item() * 100) > self.positive_thresh * 100:\n",
    "                    fcolor = \"firebrick\"\n",
    "                rush_prob = ax.text(y, x, \"%i%%\" % int(pred[0][playerInd].item() * 100), va='center', ha='center', color=fcolor, size='large', fontstretch = 'condensed', weight = 'bold', zorder = 4, clip_on = True)\n",
    "                if draw_animation:\n",
    "                    patch.append(rush_prob)\n",
    "            else:\n",
    "                color = \"black\"\n",
    "                bcolor = \"white\"\n",
    "                line_color = \"orange\"\n",
    "                if row.pff_role == 'Pass Block':\n",
    "                    bcolor = \"orange\"\n",
    "                    if blocking_df is not None:\n",
    "                        # Draw blocking lines from one player to blocked player\n",
    "                        blocking_data = blocking_df[(blocking_df.nflId == row.nflId)]\n",
    "                        blocker_y = blocking_data.y * xpix/53.3\n",
    "                        blocker_x = blocking_data.x  * ypix/120\n",
    "                        blocked_y = blocking_data.yBlockedPlayer * xpix/53.3\n",
    "                        blocked_x = blocking_data.xBlockedPlayer  * ypix/120\n",
    "                        if row.pff_blockType in ['PT','BH']: # If blocked player is not the the blocker's initial assignment (i.e. is helping out)\n",
    "                            line_color = \"red\"\n",
    "                        if row.pff_beatenByDefender or row.pff_hitAllowed or row.pff_hurryAllowed or row.pff_sackAllowed:\n",
    "                            bcolor = \"red\"\n",
    "                        blockers = ax.plot([blocker_y, blocked_y], [blocker_x, blocked_x], c=line_color, linewidth=3, linestyle=':')\n",
    "                        if draw_animation:\n",
    "                            patch.extend(blockers)\n",
    "            \n",
    "            \n",
    "            \n",
    "            border_colors = plt.plot(y, x, 'o',c=color, ms=30, mec=bcolor, mew=3, zorder = 3)\n",
    "            if draw_animation:\n",
    "                patch.extend(border_colors)\n",
    "            \n",
    "            if row.x < min_x: \n",
    "                min_x = row.x \n",
    "            if row.x > max_x:\n",
    "                max_x = row.x \n",
    "        #total_y /= (total_prob)\n",
    "        #total_x /= (total_prob)\n",
    "        #ax.plot(total_y, total_x, 'o',c=\"purple\", ms=20, mec='white', mew=2, zorder = 6, alpha = 0.5)\n",
    "        if draw_animation:\n",
    "            football = tracking_football[(tracking_football.gameId == gameId) & (tracking_football.playId == playId) & (tracking_football.frameId == frameId)]\n",
    "            football_plot = plt.plot(football.y * xpix/53.3 , football.x * ypix/120, 'd',c='brown', ms=12, zorder = 5)\n",
    "            patch.extend(football_plot)\n",
    "        ax.set_ylim((min_x - 2) * ypix/120, (max_x + 2) * ypix/120)\n",
    "\n",
    "        if home_info.sample(1)['playDirection'].item() == 'left':\n",
    "            ax.invert_yaxis()\n",
    "        else:\n",
    "            ax.invert_xaxis()   \n",
    "        plt.tight_layout()    \n",
    "        return patch\n",
    "        \n",
    "            \n",
    "    def loop_through_val(self):\n",
    "        print(\"Gathering evaluation metrics on %s plays that were not included in the training set...\" % len(self.presnap_df_val.gamePlayId.unique())) # Note: plays are \"flipped\" so actually more test cases than what is specified here\n",
    "        \n",
    "        if self.val_dataloader is None:\n",
    "            validData_ = BlitzDataset(self.presnap_df_val, excluded_pos_list = self.excluded_pos, metrics=self.metrics, order = self.order, standardize_type=self.standardize_type, ratio_use = 1.0, training = False)\n",
    "            self.val_dataloader = DataLoader(validData_, batch_size = 64, shuffle = False, collate_fn = validData_.collate)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "\n",
    "            epoch_val_loss = 0\n",
    "            TP_total = 0\n",
    "            TN_total = 0\n",
    "            FP_total = 0\n",
    "            FN_total = 0\n",
    "            \n",
    "            TN_DL = 0\n",
    "            FP_DL = 0\n",
    "            allRushersUnblocked = 0\n",
    "            predictedRushersUnblocked = 0\n",
    "            allRushersBlocked = 0\n",
    "            predictedRushersBlocked = 0\n",
    "            unpredictedRushersUnblocked = 0\n",
    "            unblockedPredictedRusherHurries = 0\n",
    "            unblockedRusherHurries = 0\n",
    "            rusherHurries = 0\n",
    "            nonDLRushers = 0\n",
    "            nonDLUnblockedRushers = 0\n",
    "            nonDLUnblockedPredictedRushers = 0\n",
    "            nonDLPredictedRushers = 0\n",
    "            nonDLRusherHurries = 0\n",
    "            nonDLUnblockedRusherHurries = 0\n",
    "            nonDLUnblockedPredictedRusherHurries = 0\n",
    "            \n",
    "            allRushers = 0\n",
    "            for idx, sample in enumerate(self.val_dataloader):\n",
    "                pred = self.model(sample['data'].float())\n",
    "                labels = sample['labels']\n",
    "                labels = torch.tensor(np.stack([l['isRusher'] for l in sample['labels']])).float()\n",
    "\n",
    "                playerBlocked = np.stack([l['isBlocked'] for l in sample['labels']])\n",
    "                playerHit     = np.stack([l['pff_hit'] for l in sample['labels']])\n",
    "                playerSack    = np.stack([l['pff_sack'] for l in sample['labels']])\n",
    "                playerHurry   = np.stack([l['pff_hurry'] for l in sample['labels']])\n",
    "                #playerPos      = np.stack([l['playerPos'] for l in sample['labels'] if (('LB' in l['playerPos']) or ('S' in l['playerPos']) or ('CB' in l['playerPos'])])\n",
    "                playerDL      = np.stack([[p.replace(\"O\",\"\").replace(\"M\",\"\").replace(\"W\",\"\") not in ['LB', 'SS', 'FS', 'CB'] for p in l['playerPos']]for l in sample['labels'] ])\n",
    "                pred = torch.nn.functional.sigmoid(pred)\n",
    "\n",
    "                \n",
    "                affectsQB = np.max((playerHit, playerSack, playerHurry), axis = 0) # Sacks + Hurries + Hits\n",
    "                allRushersUnblocked            += np.sum(np.logical_and(np.array(labels) == 1, playerBlocked == 0))\n",
    "                predictedRushersUnblocked      += np.sum(np.logical_and(np.array(labels) == 1, np.logical_and(playerBlocked == 0, np.array(pred) >= self.positive_thresh)))\n",
    "                allRushersBlocked              += np.sum(np.logical_and(np.array(labels) == 1, playerBlocked == 1))\n",
    "                predictedRushersBlocked        += np.sum(np.logical_and(np.array(labels) == 1, np.logical_and(playerBlocked == 1, np.array(pred) >= self.positive_thresh)))\n",
    "                unpredictedRushersUnblocked    += np.sum(np.logical_and(np.array(labels) == 1, np.logical_and(playerBlocked == 0, np.array(pred) <= self.positive_thresh)))\n",
    "                unblockedPredictedRusherHurries+= np.sum(np.logical_and(np.array(labels) == 1, np.logical_and(playerBlocked == 0, np.logical_and(np.array(pred) >= self.positive_thresh, affectsQB == 1))))\n",
    "                unblockedRusherHurries         += np.sum(np.logical_and(np.array(labels) == 1, np.logical_and(playerBlocked == 0, affectsQB == 1)))\n",
    "                rusherHurries                  +=  np.sum(np.logical_and(np.array(labels) == 1, affectsQB == 1))\n",
    "                \n",
    "                nonDLUnblockedRushers                += np.sum(np.logical_and(np.array(labels) == 1, np.logical_and(playerBlocked == 0, playerDL == 0)))\n",
    "                nonDLUnblockedRusherHurries          += np.sum(np.logical_and(np.array(labels) == 1, np.logical_and(playerBlocked == 0, np.logical_and(affectsQB == 1, playerDL == 0))))\n",
    "                nonDLRushers                         += np.sum(np.logical_and(np.array(labels) == 1, playerDL == 0))\n",
    "                nonDLRusherHurries                   += np.sum(np.logical_and(np.array(labels) == 1, np.logical_and(affectsQB == 1, playerDL == 0)))\n",
    "                nonDLUnblockedPredictedRusherHurries += np.sum(np.logical_and(np.array(labels) == 1, np.logical_and(playerBlocked == 0, np.logical_and(affectsQB == 1, np.logical_and( playerDL == 0, np.array(pred) >= self.positive_thresh)))))\n",
    "                nonDLUnblockedPredictedRushers       += np.sum(np.logical_and(np.array(labels) == 1, np.logical_and(playerBlocked == 0, np.logical_and( playerDL == 0, np.array(pred) >= self.positive_thresh))))\n",
    "                nonDLPredictedRushers                += np.sum(np.logical_and(np.array(labels) == 1, np.logical_and( playerDL == 0, np.array(pred) >= self.positive_thresh)))\n",
    "                                                              \n",
    "                TP_total += np.sum(np.logical_and(np.array(pred) >  self.positive_thresh, np.array(labels) == 1))\n",
    "                TN_total += np.sum(np.logical_and(np.array(pred) <= self.positive_thresh, np.array(labels) == 0))\n",
    "                FP_total += np.sum(np.logical_and(np.array(pred) >  self.positive_thresh, np.array(labels) == 0))\n",
    "                FN_total += np.sum(np.logical_and(np.array(pred) <= self.positive_thresh, np.array(labels) == 1))\n",
    "\n",
    "                TN_DL    += np.sum(np.logical_and(np.array(pred) <= self.positive_thresh, np.logical_and(np.array(labels) == 0, playerDL == 1)))\n",
    "                FP_DL    += np.sum(np.logical_and(np.array(pred) >= self.positive_thresh, np.logical_and(np.array(labels) == 0, playerDL == 1)))\n",
    "                \n",
    "            RECALL    = TP_total / (max(TP_total + FN_total, 1)) # Of all blitzers, what percentage were predicted to be blitzers\n",
    "            PRECISION = TP_total / (max(TP_total + FP_total, 1)) # Of all predicted blitzers, what percentage are actually blitzers?\n",
    "            ACCURACY  = (TP_total + TN_total) / (TP_total + TN_total + FP_total + FN_total)\n",
    "            #print(\"HURRIES + HITS + SACKS BY UNBLOCKED PLAYERS: %i%%\\nHURRIES + HITS + SACKS BY PREDICTED UNBLOCKED PLAYERS: : %i%%\\nACCURACY: %i%%\\n\" % (RECALL * 100, PRECISION * 100, ACCURACY * 100))\n",
    "            TOTAL_RUSHERS = TP_total + FN_total\n",
    "            \n",
    "            REAL_LIFE_RECALL = allRushersBlocked/(max(allRushersBlocked + allRushersUnblocked, 1))\n",
    "            blockedUnpredictedRushers = allRushersBlocked - predictedRushersBlocked\n",
    "            #REAL_LIFE_PRECISION = allRushersBlocked/(max(allRushersBlocked + allRushersUnblocked, 1))\n",
    "            #print(\"ALL UNBLOCKED RUSHERS: %i\\nPREDICTED UNBLOCKED RUSHERS: %i\\nALL BLOCKED RUSHERS: %i\\nALL PREDICTED BLOCKED RUSHERS: %i\\nRUSHERS NOT PREDICTED BUT BLOCKED: %i\\n\" % (allRushersUnblocked, predictedRushersUnblocked, allRushersBlocked, predictedRushersBlocked, blockedUnpredictedRushers))\n",
    "            print(\"\\nTotal number of pass rushers analyzed: %i\\n\" % TOTAL_RUSHERS)\n",
    "            print(\" \\\n",
    "                Pass rushers that were PREDICTED but UNBLOCKED (i.e. ML Algorithm better): %i\\n \\\n",
    "                Pass rushers NOT PREDICTED but BLOCKED (i.e. human better): %i\\n \\\n",
    "                Pass rushers PREDICTED and BLOCKED (i.e. both human and ML Algorithm are correct!): %i\\n \\\n",
    "                Pass rushers NOT PREDICTED and UNBLOCKED (i.e. both human and ML Algorithm were wrong): %i\\n\" % (predictedRushersUnblocked, blockedUnpredictedRushers, predictedRushersBlocked, unpredictedRushersUnblocked))\n",
    "            print(\"Total pass rushers (blocked or unblocked, predicted or unpredicted) that caused a QB Hurry/Hit/Sack: %i\" % rusherHurries )\n",
    "            print(\"Total unblocked pass rushers: %i\" % allRushersUnblocked)\n",
    "            print(\"Pass rushers that were PREDICTED but unblocked and caused a QB Hurry/Hit/Sack: %i\" % unblockedPredictedRusherHurries)\n",
    "            print(\"Total number of pass rushers that were unblocked and caused a QB Hurry/Hit/Sack: %i\\n\" % unblockedRusherHurries)\n",
    "            print(\"Percentage of QB Hurry/Hit/Sacks that could have been prevented: %i%%\" % (unblockedPredictedRusherHurries/unblockedRusherHurries * 100))\n",
    "            \n",
    "            print(\"Total LB or secondary pass rushers: %i\" % nonDLRushers)\n",
    "            print(\"Total LB or secondary pass rushers (blocked or unblocked, predicted or unpredicted) that caused a QB Hurry/Hit/Sack: %i\" % nonDLRusherHurries )\n",
    "            print(\"Total unblocked LB or secondary pass rushers: %i\" % nonDLUnblockedRushers)         \n",
    "            #print(\"Total unblocked LB or secondary pass rushers: %i\" % nonDLRushers)\n",
    "            print(\"LB or secondary pass rushers that were PREDICTED but unblocked and caused a QB Hurry/Hit/Sack: %i\" % nonDLUnblockedPredictedRusherHurries)\n",
    "            print(\"Total number of LB or secondary pass rushers that were unblocked and caused a QB Hurry/Hit/Sack: %i\\n\" % nonDLUnblockedRusherHurries)\n",
    "            print(\"Percentage of QB Hurry/Hit/Sacks from LB or secondary pass rushers that could have been prevented: %i%%\" % (nonDLUnblockedPredictedRusherHurries/nonDLUnblockedRusherHurries * 100))\n",
    "            print(\"LB or secondary pass rushers PREDICTED: %i\\n\" % nonDLPredictedRushers)\n",
    "            print(\"LB or secondary pass rushers PREDICTED and UNBLOCKED: %i\\n\" % nonDLUnblockedPredictedRushers)\n",
    "            \n",
    "            print(\"True Negative Defensive Linemen Predictions: %i\" % TN_DL)\n",
    "            print(\"False Positive Defensive Linemen Predictions: %i\" % FP_DL)\n",
    "            \n",
    "            print(\"REAL LIFE RECALL: %i%%\\n\" % int(REAL_LIFE_RECALL * 100))\n",
    "            print(\"RECALL: %i%%\\nPRECISION: %i%%\\nACCURACY: %i%%\\n\" % (RECALL * 100, PRECISION * 100, ACCURACY * 100))\n",
    "            print(\"TP: %i\\nTN: %i\\nFP: %i\\nFN: %i\" % (TP_total, TN_total, FP_total, FN_total))\n",
    "            \n",
    "    def run_once(self, gameId = None, playId = None, get_validation_stats = False, draw_animation = False):\n",
    "        if gameId is not None and playId is not None:\n",
    "            if draw_animation:\n",
    "                play_df, play_labels, play_pred = self.analyze_a_play(gameId, playId, frameId = 'all')\n",
    "                play_blocking_df   = self.get_blocking_data(play_df)\n",
    "                print(play_blocking_df)\n",
    "                figsize = (20,12)#(12,5.33)\n",
    "\n",
    "                fig = plt.figure(figsize = figsize)\n",
    "                plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "                plt.margins(0, 0)\n",
    "                ax = fig.gca()\n",
    "                ax.set_aspect('equal', 'box')\n",
    "                fig.patch.set_visible(False)\n",
    "                ax.axis('off')\n",
    "                yardlineNumber, yardsToGo = self.get_yardline_info(play_df, gameId, playId)\n",
    "                ax = create_football_field(ax, highlight_line=True, highlight_line_number=yardlineNumber, highlight_first_down_line=True, yards_to_go=yardsToGo, figsize = figsize)\n",
    "                ims = [[]]\n",
    "                \n",
    "                play_frames_list = np.linspace(1, int(play_df.frameId.max()), int(play_df.frameId.max())).astype(int)\n",
    "                for frame in play_frames_list:\n",
    "                    if frame % 10 == 0:\n",
    "                        print(\"%s%% COMPLETED\" % int(frame/len(play_frames_list) * 100))\n",
    "                    \n",
    "                    frame_df = play_df[play_df.frameId == frame]\n",
    "                    frame_blocking_df   = self.get_blocking_data(frame_df)\n",
    "                    patch = self.draw_play(gameId, playId, frame_df, play_labels, play_pred[frame-1].unsqueeze(0), frameId = frame, blocking_df = frame_blocking_df, draw_animation=True, ax = ax, figsize=figsize)\n",
    "                    if frame <=6: \n",
    "                        ims.append(patch) # append twice to slow-mo\n",
    "                    ims.append(patch)\n",
    "                play_animation = animation.ArtistAnimation(fig, ims, repeat=False)\n",
    "                writer = FFMpegWriter(fps=5)\n",
    "                play_animation.save('animation.mp4', writer=writer)\n",
    "            else:   \n",
    "                play_df, play_labels, play_pred = self.analyze_a_play(gameId, playId, frameId = [2])\n",
    "                play_blocking_df   = self.get_blocking_data(play_df)\n",
    "                self.draw_play(gameId, playId, play_df, play_labels, play_pred, blocking_df = play_blocking_df)\n",
    "\n",
    "            # The animation is saved as a video with the name animation.mp4. Set the fps higher if you want a faster movement.\n",
    "\n",
    "\n",
    "        if get_validation_stats:\n",
    "            self.loop_through_val()\n",
    "\n",
    "which_model = 'last' # 'last', 'best', or '<folder name>' Only 'last' will work if SAVE_WEIGHTS has been False for previous training sessions\n",
    "\n",
    "inference_loader = Inference(presnap_df, presnap_df_val, which_model = which_model)\n",
    "inference_loader.run_once(get_validation_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13958a-5223-497f-8714-f55522371315",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = presnap_df_val[(presnap_df_val.pff_sack==1) & (presnap_df_val.blitzId.isin([1,2]))].sample()\n",
    "gameId = int(sample.gameId)# 2021101400 #2021100300\n",
    "playId = int(sample.playId)# 962 #1632\n",
    "inference_loader.run_once(gameId, playId)\n",
    "\n",
    "sample = presnap_df_val[(presnap_df_val.blitzId.isin([1,2]))].sample()\n",
    "gameId = int(sample.gameId)# 2021101400 #2021100300\n",
    "playId = int(sample.playId)# 962 #1632\n",
    "inference_loader.run_once(gameId, playId)\n",
    "\n",
    "sample = presnap_df_val.sample()\n",
    "gameId = int(sample.gameId)# 2021101400 #2021100300\n",
    "playId = int(sample.playId)# 962 #1632\n",
    "inference_loader.run_once(gameId, playId)\n",
    "\n",
    "sample = presnap_df_val.sample()\n",
    "gameId = int(sample.gameId)# 2021101400 #2021100300\n",
    "playId = int(sample.playId)# 962 #1632\n",
    "inference_loader.run_once(gameId, playId)\n",
    "\n",
    "sample = presnap_df_val.sample()\n",
    "gameId = int(sample.gameId)# 2021101400 #2021100300\n",
    "playId = int(sample.playId)# 962 #1632\n",
    "inference_loader.run_once(gameId, playId)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
